# -*- coding: utf-8 -*-
"""Projeto_Classificacao_TheBigBangTheory.ipynb

Automatically generated by Colab.

Original file is located at
    https://colab.research.google.com/drive/1j9a_wCkAgoc21loftIdFo4K6N_Va8vqD
"""

!pip install keras.utils

# Commented out IPython magic to ensure Python compatibility.
# %matplotlib inline

import os

import random
import numpy as np
import keras
import cv2

from google.colab.patches import cv2_imshow

import matplotlib.pyplot as plt
from matplotlib.pyplot import imshow
from tensorflow.keras import applications
from tensorflow.keras.preprocessing import image
from keras.applications.imagenet_utils import preprocess_input
from keras.models import Sequential
from keras.layers import Dense, Dropout, Flatten, Activation
from keras.layers import Conv2D, MaxPooling2D
from keras.models import Model
from tensorflow.keras.utils import to_categorical
face_cascade = cv2.CascadeClassifier('/content/drive/MyDrive/Colab_MachineLearning/CienciaDadosMachineLearning/FormacaoMachineLearningSpecialist/ProjetoBigBangTheory/haarcascade_frontalface_default.xml')

def get_image(path):
    img = image.load_img(path, target_size=(224, 224))
    x = image.img_to_array(img)
    x = np.expand_dims(x, axis=0)
    x = preprocess_input(x)
    return img, x

root = '/content/drive/MyDrive/Colab_MachineLearning/CienciaDadosMachineLearning/FormacaoMachineLearningSpecialist/ProjetoBigBangTheory/dataset'
train_split, val_split = 0.7, 0.15
categorias = [x[0] for x in os.walk(root) if x[0]][1:]
print(categorias)

def carregar_imagens(categorias):
  data = []
  for c, category in enumerate(categorias):
      images = [os.path.join(dp, f) for dp, dn, filenames
                in os.walk(category) for f in filenames
                if os.path.splitext(f)[1].lower() in ['.jpg','.png','.jpeg']]
      print(images)
      for img_path in images:
          img, x = get_image(img_path)
          print(img)
          data.append({'x':np.array(x[0]), 'y':c})
  num_classes = len(categorias)
  print(num_classes)
  return data, num_classes;

data = []
data, num_classes = carregar_imagens(categorias)

"""Embaralha os dados no objeto data para depois dividir em dados de treino e dados de validação. Os dados inicialmente foram carregados na ordem de leitura das categorias."""

random.shuffle(data)

idx_val = int(train_split * len(data))
idx_test = int((train_split + val_split) * len(data))
train = data[:idx_val]
val = data[idx_val:idx_test]
test = data[idx_test:]

x_train, y_train = np.array([t["x"] for t in train]), [t["y"] for t in train]
x_val, y_val = np.array([t["x"] for t in val]), [t["y"] for t in val]
x_test, y_test = np.array([t["x"] for t in test]), [t["y"] for t in test]

"""Transforma imagens em escala de cinza."""

# normalize data
x_train = x_train.astype('float32') / 255.
x_val = x_val.astype('float32') / 255.
x_test = x_test.astype('float32') / 255.

# convert labels to one-hot vectors
# Ensure y_train, y_val, and y_test are lists of integers before converting to one-hot
y_train = to_categorical(np.array(y_train).flatten(), num_classes)
y_val = to_categorical(np.array(y_val).flatten(), num_classes)
y_test = to_categorical(np.array(y_test).flatten(), num_classes)

# summary
print("finished loading %d images from %d categories"%(len(data), num_classes))
print("train / validation / test split: %d, %d, %d"%(len(x_train), len(x_val), len(x_test)))
print("training data shape: ", x_train.shape)
print("training labels shape: ", y_train.shape)

images = [os.path.join(dp, f) for dp, dn, filenames in os.walk(root) for f in filenames if os.path.splitext(f)[1].lower() in ['.jpg','.png','.jpeg']]
idx = [int(len(images) * random.random()) for i in range(8)]
imgs = [image.load_img(images[i], target_size=(224, 224)) for i in idx]
concat_image = np.concatenate([np.asarray(img) for img in imgs], axis=1)
plt.figure(figsize=(16,4))
plt.imshow(concat_image)

x_train.shape[1:]

# build the network
model = Sequential()
print("Input dimensions: ",x_train.shape[1:])

model.add(Conv2D(32, (3, 3), input_shape=x_train.shape[1:]))
model.add(Activation('relu'))
model.add(MaxPooling2D(pool_size=(2, 2)))

model.add(Conv2D(32, (3, 3)))
model.add(Activation('relu'))
model.add(MaxPooling2D(pool_size=(2, 2)))

model.add(Dropout(0.25))

model.add(Conv2D(32, (3, 3)))
model.add(Activation('relu'))
model.add(MaxPooling2D(pool_size=(2, 2)))

model.add(Conv2D(32, (3, 3)))
model.add(Activation('relu'))
model.add(MaxPooling2D(pool_size=(2, 2)))

model.add(Dropout(0.25))

model.add(Flatten())
model.add(Dense(256))
model.add(Activation('relu'))

model.add(Dropout(0.5))

model.add(Dense(num_classes))
model.add(Activation('softmax'))

model.summary()

# compile the model to use categorical cross-entropy loss function and adadelta optimizer
model.compile(loss='categorical_crossentropy',
              optimizer='adam',
              metrics=['accuracy'])

history = model.fit(x_train, y_train,batch_size=64,epochs=10,validation_data=(x_val, y_val))

history.history

fig = plt.figure(figsize=(16,4))
ax = fig.add_subplot(121)
ax.plot(history.history["val_loss"])
ax.set_title("validation loss")
ax.set_xlabel("epochs")

ax2 = fig.add_subplot(122)
ax2.plot(history.history["val_accuracy"])
ax2.set_title("validation accuracy")
ax2.set_xlabel("epochs")
ax2.set_ylim(0, 1)

plt.show()

loss, accuracy = model.evaluate(x_test, y_test, verbose=0)
print('Test loss:', loss)
print('Test accuracy:', accuracy)

img, x = get_image('/content/drive/MyDrive/Colab_MachineLearning/CienciaDadosMachineLearning/FormacaoMachineLearningSpecialist/ProjetoBigBangTheory/dataset/howard/howard10.png')
probabilities = model.predict([x])

probabilities

# Commented out IPython magic to ensure Python compatibility.
# %cd '/content/drive/MyDrive/Colab_MachineLearning/CienciaDadosMachineLearning/FormacaoMachineLearningSpecialist/ProjetoBigBangTheory/'
model.save("bigbemtheory_model.h5")

reconstructed_model = keras.models.load_model("/content/drive/MyDrive/Colab_MachineLearning/CienciaDadosMachineLearning/FormacaoMachineLearningSpecialist/ProjetoBigBangTheory/bigbemtheory_model.h5")

img, x = get_image('/content/drive/MyDrive/Colab_MachineLearning/CienciaDadosMachineLearning/FormacaoMachineLearningSpecialist/ProjetoBigBangTheory/dataset/howard/howard10.png')
predict_reconstructed_model = reconstructed_model.predict([x])

predict_reconstructed_model

def reconheceImagem(modelo, arquivo, categorias): # Add categorias as a parameter
    from google.colab.patches import cv2_imshow
    """
    Identifica pessoas em uma imagem usando um modelo e categorias fornecidas.

    Args:
        model (keras.Model): O modelo treinado para classificação de pessoas.
        arquivo (str): O caminho para o arquivo de imagem.
        categorias (list): Uma lista de strings, onde cada string é o nome de uma categoria de pessoa.
    """
    img = cv2.imread(arquivo) # Read the image
    print("Imagem Lida :")
    cv2_imshow(img)

    if img is None:
        print(f"Erro ao ler a imagem: {arquivo}")
        return

    gray = cv2.cvtColor(img, cv2.COLOR_BGR2GRAY)
    print("Imagem em escala de Cinza :")
    cv2_imshow(gray)

    faces = face_cascade.detectMultiScale(gray, 1.3, 5)
    print("Faces:", faces)

    # If no faces are found, display the original image and exit
    if not np.any(faces):
        print("Nenhuma face encontrada na imagem.")
        from google.colab.patches import cv2_imshow
        cv2_imshow(img)
        return

    # Process each detected face
    for (x, y, w, h) in faces:

        rosto = img[y:y+h, x:x+w]
        print("Rosto:")
        cv2_imshow(rosto)

        print("W e H:")
        print(w)
        print(h)

        # Resize the face to match the model's input shape and preprocess
        rosto = cv2.resize(rosto, (224, 224))
        x_rosto = image.img_to_array(rosto)
        x_rosto = np.expand_dims(x_rosto, axis=0)
        x_rosto = preprocess_input(x_rosto)

        # Remove the following line as it causes a TypeError.
        # x_rosto is a preprocessed array for the model, not a displayable image format.
        # cv2_imshow(x_rosto)

        # Predict the category
        probabilities = modelo.predict(x_rosto)

        print("Probabilidades:")
        print(probabilities)

        # Get the class with the highest probability
        predicted_class = np.argmax(probabilities[0])

        # Get the corresponding category name
        predicted_name = categorias[predicted_class].split('/')[-1]

        font = cv2.FONT_HERSHEY_SIMPLEX

        # Put text and rectangle based on the predicted name
        cv2.putText(img, predicted_name,(x, y - 10), font, 1,(255,0,0),2,cv2.LINE_AA)
        cv2.rectangle(img,(x,y),(x+w,y+h),(255,0,0),2)

        print("Imagem após a marcação do retangulo:")
        cv2_imshow(img)

    # Resize the image for display
    img = cv2.resize(img, (int(0.75 * img.shape[1]), int(0.75 * img.shape[0])))

    # Display the image with detections
    print("Foto com Detecção:")
    cv2_imshow(img)

    cv2.destroyAllWindows()

# Example usage (replace with your actual model, image path, and categories):
# image_path = '/content/drive/MyDrive/path/to/your/image.jpg'
# reconheceImagem(reconstructed_model, image_path, categorias)

# Example usage:
image_path = '/content/drive/MyDrive/Colab_MachineLearning/CienciaDadosMachineLearning/FormacaoMachineLearningSpecialist/ProjetoBigBangTheory/fotodevalidacao.png' # Replace with the path to your image
reconheceImagem(reconstructed_model, image_path, categorias)
